import streamlit as st
from streamlit_webrtc import webrtc_streamer
import mediapipe as mp
import numpy as np
import tensorflow as tf
import av

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
@st.cache_resource
def load_model():
    return tf.keras.models.load_model("sign_language_model.h5")

model = load_model()

# Ø¥Ø¹Ø¯Ø§Ø¯ Mediapipe Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£ÙŠØ¯ÙŠ
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=2,
    min_detection_confidence=0.5
)

# ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
sign_language_classes = [
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Ø¹Ø°Ø±Ù‹Ø§",
    "", "Ø·Ø¹Ø§Ù…", "", "", "Ù…Ø±Ø­Ø¨Ù‹Ø§", "Ù…Ø³Ø§Ø¹Ø¯Ø©", "Ù…Ù†Ø²Ù„", "Ø£Ù†Ø§", "Ø£Ø­Ø¨Ùƒ", "", "", "",
    "", "", "Ù„Ø§", "", "", "Ù„Ùˆ Ø³Ù…Ø­Øª", "", "", "", "", "Ø´ÙƒØ±Ù‹Ø§", "", "", "",
    "", "", "Ù†Ø¹Ù…", ""
]

# Ø¯Ø§Ù„Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ù…
def process_landmarks(hand_landmarks):
    landmarks = []
    for lm in hand_landmarks.landmark:
        landmarks.extend([lm.x, lm.y, lm.z])
    return landmarks

# Ø¯Ø§Ù„Ø© Ø§Ù„ØªØµÙ†ÙŠÙ
def classify_gesture(image):
    image_rgb = np.array(image)
    result = hands.process(image_rgb)

    if result.multi_hand_landmarks:
        landmarks_array = np.array(process_landmarks(result.multi_hand_landmarks[0])).reshape(1, -1)
        prediction = model.predict(landmarks_array, verbose=0)
        class_id = np.argmax(prediction[0])
        confidence = prediction[0][class_id]
        return sign_language_classes[class_id], confidence
    return None, None

# Ø¯Ø§Ù„Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… WebRTC
class VideoProcessor:
    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        gesture, confidence = classify_gesture(img)

        if gesture:
            text = f"Ø§Ù„Ø¥Ø´Ø§Ø±Ø©: {gesture} | Ø§Ù„Ø«Ù‚Ø©: {confidence:.2%}"
            cv2.putText(img, text, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)

        return av.VideoFrame.from_ndarray(img, format="bgr24")

# ğŸš€ **ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚**
st.title("ğŸ”µğŸŸ¢ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù„ØºØ© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù„Ù„ØµÙ… ÙˆØ§Ù„Ø¨ÙƒÙ… ğŸŸ¢ğŸ”µ")

# âœ… **ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… streamlit-webrtc**
webrtc_streamer(key="camera", video_processor_factory=VideoProcessor)

# ğŸ“Œ **Ø¥Ø¶Ø§ÙØ© Ø²Ø± Ø¥ÙŠÙ‚Ø§Ù**
if st.button("Ø¥ÙŠÙ‚Ø§Ù"):
    st.write("ğŸ“Œ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§.")
